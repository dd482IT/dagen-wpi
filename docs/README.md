# Data Access Generator 

## Purpose and Features
Use this package in your software build process to generate SQL/JSON SELECT
queries, INSERT/UPDATE/DELETE ("mod") statements, and matching types from
simple text (yaml) specifications.

#### Fetch nested data spanning any number of related tables via a single query

The generated queries employ the SQL/JSON capabilities of supported databases,
currently PostgreSQL and Oracle, to allow fetching data from any number of
related tables in a single query operation. Queries can be configured to either
return data as a single aggregate json array containing all results, or streamed
via multiple result rows.

####  No runtime library support necessary

The queries and mod statements are generated as plain SQL text, which can be
included in an application as static resources, and executed directly in the
DMBS via plain JDBC or Spring Jdbc, etc, with no extra library needed at
run-time.

#### Result type generation

Types can also be generated for each query which will match the query results
structure precisely, including only the fields actually selected from source
tables in each specific part of the query. Field nullability is also
represented in generated types, as derived from database metadata. The query
results can be directly serialized to the top result type using common
libraries, such as Jackson in Java, or via direct cast in Typescript.

#### Find errors in data access code at build time

The database metadata which is generated by the tool allows for validation
of any table and field names and table relationships referenced in a query
or modification statement specification. This enusures that the queries and
types generated are consistent with the state of the database structure, with
failures indicated at build time. An additional level of safety is afforded
by accessing query results only via the auto-generated result types which are
guaranteed to match the actual query results.

#### Parameter safety

Both queries and modification statements can be parameterized. For the common
case that parameters found in these statements are bound directly to table
fields, for either comparison in the case of queries, or to set/insert data for
mod statements, such parameters are declared in generated source code as
constants with names derived from the field name. This makes it easy to keep
parameters valid vs the fields they target as changes to either the database
or the query/mod statements are made, with most errors identified at
statement generation time.

#### Why not just use joins to fetch related table data?

Joins *alone* are not the right tool for fetching data for the important case
that data from *independent child tables* of a parent table are needed in a
query. A join of a parent with independent child tables joined to the parent
yields results representing all combinations of the rows of the independent
child tables, whereas ideally we only need to fetch a number of rows equal to
the sum of the numbers of child rows related to the parent. Likewise the join
approach would produce a large amount of duplicated data (which occures to a 
lesser degree even with a simple parent/child join), which would have to
be "de-convolved" in the receiving client from the combinations introduced by
the cartesion product operation. Using joins for such a case would be
inefficient, not to mention tedious and error-prone - definitely not the right
tool for this job!

Instead, we can fetch the child collections as sub-selects of the parent query,
using aggregating SQL/JSON functions such as json_arrayagg() to collect
related values, and utilizing json_object() to make the json objects themselves.
This method works wonderfully to fetch nested data, but the queries can be
difficult to write and to verify to be correct manually. It's one of the
primary purposes of this library to generate these kinds of queries easily and
matching types, using a simple specification format which is checked against
database metadata for correctness. 

## Usage
#### Workflow

1) Generate database metadata, stored in a json or yaml file. This should be
done whenever the database has changes that should be incorporated.
2) Create a queries specification file, describing for each query a starting or
"top" table, its fields to be included, any parent and child tables of
the top table, fields and parent and child tables of those parent and child
tables, and so on to any depth.  
3) Run the tool specifying the above two files and the output directories for
the generated SQL and source code files. This step can be run as part of the
application build process.
4) At application run time, load the SQL resource file for a query, submit to
the database, specifying any embedded parameter values, and deserialize results
to the generated top level type for the query.


#### Example
![Example schema diagram](images/DrugsSchema.png)

TODO: diagram showing independent child tables
 N1 + N2 + N3 results for SQL/JSON
 N1 * N2 * N3 from a join.


